{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecoNet",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNf9RtX9muZBoHIb3wWq2oC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanyaanand/RecoNet/blob/master/RecoNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d7QrJvJZ24i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-4ISqtrj72L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.metrics import recall_score\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdT7pDEGR0gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "utils functions\n",
        "\"\"\"\n",
        "def adjust_learning_rate(optimizer, lr, lr_decay):\n",
        "\n",
        "    for group in optimizer.param_groups:\n",
        "        if 'step' not in group:\n",
        "            group['step'] = 0\n",
        "        group['step'] += 1\n",
        "\n",
        "        group['lr'] = lr / (1 + group['step'] * lr_decay)\n",
        "\n",
        "\n",
        "def create_optimizer(model, new_lr, opt, lr_decay, wd):\n",
        "    # setup optimizer\n",
        "    if opt == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=new_lr,\n",
        "                              momentum=0.9, dampening=0.9,\n",
        "                              weight_decay=args.wd)\n",
        "    elif opt == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=new_lr,\n",
        "                               weight_decay=wd)\n",
        "    elif opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(model.parameters(),\n",
        "                                  lr=new_lr,\n",
        "                                  lr_decay=lr_decay,\n",
        "                                  weight_decay=wd)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def Filtering(ratings, movies, threshold = 50):\n",
        "    \"\"\"\n",
        "      Args : \n",
        "        input : rating = np array of user rating of dimension N X 4, where N is the number of users and columns are user id, movie id, star, timestamp. \n",
        "                movies = np array of user rating of dimension N X 3, where N is the number of movies and columns are movie id, movie name, movie genre\n",
        "                threshold = for removing data below threshold value\n",
        "        output : a list containing two np array(rating and movie)\n",
        "        Ops : downsampling \n",
        "    \"\"\"\n",
        "    count = {} \n",
        "    for i in ratings:\n",
        "        key = i[1]\n",
        "        if key in count:\n",
        "            count[key] +=1\n",
        "        else:\n",
        "            count[key] = 1\n",
        "\n",
        "    fast = {}\n",
        "    for i in movies:\n",
        "        key = i[0]\n",
        "        fast[key] = i\n",
        "\n",
        "    Train_data = []\n",
        "    Test_data = []\n",
        "    append = {}\n",
        "    genres = []\n",
        "    for i in ratings:\n",
        "        key = i[1]\n",
        "        if count[key] > threshold:\n",
        "            if key in append:\n",
        "                if np.random.rand() >= 0.33:\n",
        "                  Train_data.append(i)\n",
        "                else:\n",
        "                  Test_data.append(i)\n",
        "\n",
        "            else:\n",
        "                append[key] = 1\n",
        "                Train_data.append(i)\n",
        "                genres.append(fast[key])\n",
        "\n",
        "    temp = indxing(Train_data, Test_data, genres)\n",
        "    return temp\n",
        "\n",
        "def indxing(Train_list, Test_list, genres_list):\n",
        "    \"\"\"\n",
        "        movie id in the dataset contains gap in between, thus this function map gap id to ungap id \n",
        "    \"\"\"\n",
        "    m_index = {}\n",
        "    for i in range(len(genres_list)):\n",
        "        m_index[genres_list[i][0]] = i + 1\n",
        "\n",
        "    train_data = []\n",
        "    for i in Train_list:\n",
        "        temp = i\n",
        "        temp[1] = m_index[i[1]]\n",
        "        train_data.append(temp)\n",
        "\n",
        "    test_data = []\n",
        "    for i in Test_list:\n",
        "        temp = i\n",
        "        temp[1] = m_index[i[1]]\n",
        "        test_data.append(temp)\n",
        "\n",
        "    movie = []\n",
        "    for i in range(len(genres_list)):\n",
        "        temp = genres_list[i]\n",
        "        temp[0] = m_index[genres_list[i][0]]\n",
        "        movie.append(temp) \n",
        "\n",
        "    return [np.array(train_data), np.array(test_data), np.array(movie)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qlYs_9NjYlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6ef20faa-14de-4568-9649-db3c68285442"
      },
      "source": [
        "\n",
        "movie_genre = {\"Action\" : 1, \n",
        "    \"Adventure\" : 2,\n",
        "    \"Animation\" : 3,\n",
        "    \"Children\" : 4,\n",
        "    \"Comedy\" : 5,\n",
        "    \"Crime\" : 6,\n",
        "    \"Documentary\" : 7,\n",
        "    \"Drama\" : 8,\n",
        "    \"Fantasy\" : 9,\n",
        "    \"Film-Noir\" : 10, \n",
        "    \"Horror\" : 11,\n",
        "    \"Musical\" : 12,\n",
        "    \"Mystery\" : 13,\n",
        "    \"Romance\" : 14,\n",
        "    \"Sci-Fi\" : 15,\n",
        "    \"Thriller\" : 16,\n",
        "    \"War\" : 17,\n",
        "    \"Western\" : 18\n",
        "  }\n",
        "a = pd.read_csv(\"ratings.csv\")\n",
        "print(a.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB89Dvg32azH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4f777eff-7e91-47b8-9568-173288788eec"
      },
      "source": [
        "b = pd.read_csv(\"movies.csv\")\n",
        "print(b.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   movieId  ...                                       genres\n",
            "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
            "1        2  ...                   Adventure|Children|Fantasy\n",
            "2        3  ...                               Comedy|Romance\n",
            "3        4  ...                         Comedy|Drama|Romance\n",
            "4        5  ...                                       Comedy\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLXgIyrI1sqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rating = np.array(a.values)\n",
        "genres = np.array(b.values)\n",
        "temp = Filtering(rating, genres)\n",
        "TrainData, TestData, genres = temp[0], temp[1], temp[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOBgwDowVsiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Emdedding(nn.Module):\n",
        "\tdef __init__(self, hidden_size, input_size, output_size):\n",
        "\t\tsuper(Emdedding, self).__init__()\n",
        "\t\tself.lookup = nn.Linear(input_size, hidden_size,bias=False)\n",
        "\t\tself.prediction = nn.Linear(hidden_size, output_size, bias=False)\n",
        "\t\tself.relu = nn.ReLU()\n",
        "\t\tself.BN = nn.BatchNorm1d(hidden_size)\n",
        "\t\tself.Drop = nn.Dropout(0.33)\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\t# x_aux = self.Drop(self.relu(self.BN(self.lookup(x)))) # uncomment this line for incorporating BN and dropout\n",
        "\t\tx_aux = (self.lookup(x))\\\n",
        "\t\t\t/torch.abs(x.sum(-1).view(x.size()[0], 1) + 1e-8*torch.ones([x.size()[0], 1]).cuda())\n",
        "\t\tx = (self.prediction(x_aux))\n",
        "\t\treturn x, x_aux\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDTzXqoNjNav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class dataloader(Dataset):\n",
        "\t\n",
        "\tdef __init__(self, rating_list, genres_list, movie_genre, mode = \"Train\"):\n",
        "\t\t\"\"\"\n",
        "\t\t\tArgs : numpy array of rating, numpy array of movies, dict. of movie genre to integer, mode of operation\n",
        "\t\t\"\"\"\n",
        "\t\tself.rating_list = rating_list\n",
        "\t\tself.genres_list = genres_list\n",
        "\t\tself.movie_genre = movie_genre\n",
        "\t\tself.length = rating_list.shape[0]\n",
        "\t\tself.n_users = len(np.unique(rating_list[:, 0]))# number of unique users\n",
        "\t\tself.n_movies = len(genres_list)# number of movies\n",
        "\t\tself.n_attr = len(movie_genre) + 1# number of features\n",
        "\t\tself.un_user = np.unique(rating_list[:, 0])\n",
        "\n",
        "\tdef UserData(self, user):\n",
        "\t\t\"\"\"\n",
        "\t\t\tArgs : user id \n",
        "\t\t\tOutput : input vector(as mention in the paper) of dimension = #movies * #features\n",
        "\t\t\"\"\"\n",
        "\t\tphi_v = [0]*self.n_attr# attributes feature\n",
        "\t\tVv = [0]*self.n_movies# movies feature\n",
        "\t\tidx = np.where(self.rating_list[:, 0] == user)[0]\n",
        "\t\tmovies = self.rating_list[idx, 1]# list of movies he/she rated\n",
        "\t\tstars = self.rating_list[idx, 2]\n",
        "\t\tfor k in range(len(movies)):\n",
        "\t\t\tmovie = movies[k]\n",
        "\t\t\tstar = stars[k]\n",
        "\t\t\tif star >= 0.0:\n",
        "\t\t\t\tVv[int(movie) - 1] += 1 #  movie is 1 index\n",
        "\t\t\tx = np.where(self.genres_list[:, 0] == movie)[0]\n",
        "\t\t\tstrings = self.genres_list[x, 2][0].split(\"|\")\n",
        "\t\t\tfor string in strings:\n",
        "\t\t\t\tif string in self.movie_genre:\n",
        "\t\t\t\t\tphi_v[self.movie_genre[string] - 1] = 1 # movie_genre is 1 index\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tphi_v[18] = 1\n",
        "\n",
        "\t\treturn np.concatenate((Vv, phi_v), axis=0)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.length\n",
        "\t\n",
        "\tdef __getitem__(self, idx):\n",
        "\n",
        "\t\tX = self.UserData(self.rating_list[idx, 0])\n",
        "\t\ty = [int(self.rating_list[idx, 1] - 1)]# remove the movie\n",
        "\t\t#remove features of the movie\n",
        "\t\t# w = np.where(self.genres_list[:, 0]== self.rating_list[idx, 1])[0]\n",
        "\t\tw = self.rating_list[idx, 1] - 1\n",
        "\t\tstrings = self.genres_list[int(w), 2].split(\"|\")\t\n",
        "\t\tfor string in strings:\n",
        "\t\t\tif string in self.movie_genre:\n",
        "\t\t\t\tt = self.movie_genre[string] - 20\n",
        "\t\t\t\tX[t] -= 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tX[-1] -= 1\n",
        "\t\tX[y] = 0\n",
        "\t\tsample = {'data' : torch.Tensor(X), 'label' : torch.Tensor(y)}\n",
        "\t\treturn sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5HvIbDijKeW",
        "colab_type": "code",
        "outputId": "a7cd1e72-604c-40e6-b33c-a65aee96beb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "kwargs = {'num_workers': 8, 'pin_memory': True} \n",
        "print(\"number of training data {} nummber of users {} number of movies {}\".format(len(TrainData), len(np.unique(TrainData[:, 0])), len(np.unique(TrainData[:, 1]))))\n",
        "print(\"number of testing data {} nummber of users {} number of movies {}\".format(len(TestData), len(np.unique(TestData[:, 0])), len(np.unique(TestData[:, 1]))))\n",
        "TrainLoader = dataloader(TrainData, genres, movie_genre)\n",
        "TestLoader = dataloader(TestData, genres, movie_genre) \t \t"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training data 27332 nummber of users 604 number of movies 436\n",
            "number of testing data 13328 nummber of users 594 number of movies 436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3LlZltJi6mx",
        "colab_type": "code",
        "outputId": "32f61586-ec60-40de-957d-ed824a24a565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "net = Emdedding(1024, len(genres)+len(movie_genre)+1, len(genres))\n",
        "net.cuda()\n",
        "batch_size = 64*4\n",
        "epoch = 10\n",
        "lr = 0.01\n",
        "lr_decay = 0.01\n",
        "wt_decay = 0.0\n",
        "\n",
        "# optimizer = create_optimizer(net, lr, \"adagrad\", lr_decay, wt_decay)\n",
        "optimizer = create_optimizer(net, lr, \"adam\", lr_decay, wt_decay)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "metric_test = []\n",
        "metric_train = []\n",
        "TrainSample = torch.utils.data.DataLoader(TrainLoader, batch_size= batch_size, shuffle=True)\n",
        "TestSample = torch.utils.data.DataLoader(TestLoader, batch_size= batch_size, shuffle=False)\n",
        "\n",
        "print(\"starting training!\")\n",
        "for n_epoch in range(epoch):\n",
        "\terror = 0\n",
        "\tlabels = []\n",
        "\tlogits = []\n",
        "\tcount = 0\n",
        "\tnet.eval()\n",
        "\tfor i, batch in enumerate(TestSample):\n",
        "\t\tX = Variable(batch['data'].cuda())\n",
        "\t\ty = Variable(torch.squeeze(batch['label']).long().cuda())\n",
        "\t\ty_pred, h = net(X)\n",
        "\t\tloss = criterion(y_pred, y)\n",
        "\t\tcount+=1\n",
        "\t\terror += loss.cpu().detach().numpy()\n",
        "\t\tlabels += list(y.cpu().detach().numpy())\n",
        "\t\tlogits += list(np.argmax(F.log_softmax(y_pred, 1).cpu().detach().numpy(), axis=1))\n",
        "\trecall = recall_score(labels, logits, average='micro')\n",
        "\tmetric_test.append([n_epoch, error/count, recall])\n",
        "\tprint(\"Test : epoch {} loss {} recall {}\".format(n_epoch, error/count, recall))\n",
        "\n",
        "\t#---------------------------------------------------------------------------------------#\n",
        "\terror = 0\n",
        "\tcount = 0\n",
        "\tlabels = []\n",
        "\tlogits = []\n",
        "\tnet.train()\n",
        "\tfor i, batch in enumerate(TrainSample):\n",
        "\t\tX = Variable(batch['data'].cuda())\n",
        "\t\ty = Variable(torch.squeeze(batch['label']).long().cuda())\n",
        "\t\ty_pred, h = net(X)\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tloss = criterion(y_pred, y)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tcount +=1\n",
        "\t\terror += loss.cpu().detach().numpy()\n",
        "\t\tlabels += list(y.cpu().detach().numpy())\n",
        "\t\tlogits += list(np.argmax(F.log_softmax(y_pred, 1).cpu().detach().numpy(), axis=1))\n",
        "\tadjust_learning_rate(optimizer, lr, lr_decay)\n",
        "\trecall = recall_score(labels, logits, average='micro')\n",
        "\tmetric_train.append([n_epoch, error/count, recall])\n",
        "\tprint(\"Train : epoch {} loss {} recall {}\".format(n_epoch, error/count, recall))\n",
        " \n",
        "np.save(\"graphTrain\", metric_train)\n",
        "np.save(\"graphTest\", metric_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting training!\n",
            "Test : epoch 0 loss 6.077622368650617 recall 0.0021758703481392556\n",
            "Train : epoch 0 loss 5.2825995382861555 recall 0.054368505780769794\n",
            "Test : epoch 1 loss 4.249953467890902 recall 0.1717436974789916\n",
            "Train : epoch 1 loss 3.371436834335327 recall 0.2929899019464364\n",
            "Test : epoch 2 loss 3.478915848821964 recall 0.31865246098439376\n",
            "Train : epoch 2 loss 2.3198368047999445 recall 0.4641080052685497\n",
            "Test : epoch 3 loss 3.483758955631616 recall 0.3617196878751501\n",
            "Train : epoch 3 loss 1.788814229385875 recall 0.5627469632665008\n",
            "Test : epoch 4 loss 3.8141158211906 recall 0.37717587034813926\n",
            "Train : epoch 4 loss 1.443701661635782 recall 0.6344211912776233\n",
            "Test : epoch 5 loss 4.30821381649881 recall 0.3784513805522209\n",
            "Train : epoch 5 loss 1.1904558188447327 recall 0.7007902824528026\n",
            "Test : epoch 6 loss 4.740806939466944 recall 0.3786014405762305\n",
            "Train : epoch 6 loss 0.9743825709708384 recall 0.7675984194350944\n",
            "Test : epoch 7 loss 5.358114699147782 recall 0.3741746698679472\n",
            "Train : epoch 7 loss 0.79808912544607 recall 0.8295770525391483\n",
            "Test : epoch 8 loss 5.905288385895063 recall 0.3687725090036014\n",
            "Train : epoch 8 loss 0.6554285321280221 recall 0.8776525684179716\n",
            "Test : epoch 9 loss 6.50022797539549 recall 0.3641956782713085\n",
            "Train : epoch 9 loss 0.538673596961476 recall 0.9142031318600907\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}